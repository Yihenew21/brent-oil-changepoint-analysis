{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 1: Introduction to Change Point Modeling\n",
    "\n",
    "**Purpose**: This notebook implements a Bayesian change point model using PyMC to detect structural breaks in Brent oil price log returns and associate them with major events for the 10 Academy Week 10 Challenge (Task 2).\n",
    "\n",
    "**Objectives**:\n",
    "- Load and prepare preprocessed Brent oil price data.\n",
    "- Build and run a Bayesian change point model on log returns.\n",
    "- Interpret results to identify change points and quantify impacts.\n",
    "- Associate change points with events from `major_events.csv`.\n",
    "\n",
    "**Input**: `data/processed/cleaned_oil_data.csv`, `data/events/major_events.csv`\n",
    "**Output**: Plots in `results/figures/`, model results in `results/models/`, and interpretation dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad2dfac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.configdefaults): g++ not available, if using conda: `conda install gxx`\n",
      "WARNING (pytensor.configdefaults): g++ not detected!  PyTensor will be unable to compile C-implementations and will default to Python. Performance may be severely degraded. To remove this warning, set PyTensor flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import Required Libraries\n",
    "# Description: Import Python libraries for modeling, data handling, and visualization.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "# Add the project root directory\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from src.models.changepoint_model import build_changepoint_model, run_mcmc, plot_changepoint_results, interpret_changepoint\n",
    "\n",
    "# Ensure plots are displayed inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "192489bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price Data Head:\n",
      "        Date  Price  Log_Price  Log_Returns\n",
      "0 1987-05-20  18.63   2.924773          NaN\n",
      "1 1987-05-21  18.45   2.915064    -0.009709\n",
      "2 1987-05-22  18.55   2.920470     0.005405\n",
      "3 1987-05-25  18.60   2.923162     0.002692\n",
      "4 1987-05-26  18.63   2.924773     0.001612\n",
      "\n",
      "Events Data Head:\n",
      "                Event Name  Start Date         Category  \\\n",
      "0          Gulf War Begins  1990-08-02         Conflict   \n",
      "1   Asian Financial Crisis  1997-07-02   Economic Shock   \n",
      "2             9/11 Attacks  2001-09-11  Political Shock   \n",
      "3          Iraq War Begins  2003-03-20         Conflict   \n",
      "4  Global Financial Crisis  2008-09-15   Economic Shock   \n",
      "\n",
      "                                         Description  \\\n",
      "0  Iraq invades Kuwait; major geopolitical shock ...   \n",
      "1  Currency collapse across Asia affects global d...   \n",
      "2  Terror attacks create market instability and e...   \n",
      "3  U.S. invasion leads to long-term shifts in Mid...   \n",
      "4  Lehman collapse triggers global recession and ...   \n",
      "\n",
      "                                         Source Link  \n",
      "0             https://en.wikipedia.org/wiki/Gulf_War  \n",
      "1  https://www.investopedia.com/terms/a/asian-fin...  \n",
      "2  https://en.wikipedia.org/wiki/September_11_att...  \n",
      "3  https://www.history.com/topics/middle-east/ira...  \n",
      "4  https://www.imf.org/en/Publications/WP/Issues/...  \n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load Preprocessed Data\n",
    "# Description: Load preprocessed Brent oil price data and major events dataset.\n",
    "# Input: Preprocessed CSV file and events CSV file\n",
    "# Output: DataFrames for prices and events\n",
    "\n",
    "# Define file paths\n",
    "PRICE_PATH = '../data/processed/cleaned_oil_data.csv'\n",
    "EVENTS_PATH = '../data/events/major_events.csv'\n",
    "\n",
    "# Load price data\n",
    "price_df = pd.read_csv(PRICE_PATH, parse_dates=['Date'])\n",
    "\n",
    "# Load events data with quoting to handle commas in text fields\n",
    "events_df = pd.read_csv(EVENTS_PATH, quotechar='\"', quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "# Display first few rows to verify\n",
    "print(\"Price Data Head:\")\n",
    "print(price_df.head())\n",
    "print(\"\\nEvents Data Head:\")\n",
    "print(events_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abafd594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of weeks: 1853\n",
      "Log returns range: -0.0647 to 0.0676\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Prepare Data for Modeling\n",
    "# Description: Extract log returns and dates for change point modeling, downsample to weekly data.\n",
    "# Input: Preprocessed DataFrame\n",
    "# Output: Numpy array of log returns and Series of dates\n",
    "\n",
    "# Drop rows with NaN log returns (first row due to diff)\n",
    "model_df = price_df.dropna(subset=['Log_Returns'])\n",
    "\n",
    "# Downsample to weekly data\n",
    "model_df = model_df.resample('W', on='Date').mean().reset_index()\n",
    "\n",
    "# Extract log returns as numpy array\n",
    "log_returns = model_df['Log_Returns'].values\n",
    "\n",
    "# Extract corresponding dates\n",
    "dates = model_df['Date']\n",
    "\n",
    "# Get number of days\n",
    "n_days = len(log_returns)\n",
    "\n",
    "# Print data summary\n",
    "print(f\"Number of weeks: {n_days}\")\n",
    "print(f\"Log returns range: {log_returns.min():.4f} to {log_returns.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a8708c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "CompoundStep\n",
      ">Metropolis: [tau_idx]\n",
      ">NUTS: [mu_1, mu_2, sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\hp\\Desktop\\projects\\10 Acadamy \n",
       "-KAIM5\\brent-oil-changepoint-analysis\\.venv\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\hp\\Desktop\\projects\\10 Acadamy \n",
       "-KAIM5\\brent-oil-changepoint-analysis\\.venv\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 5_000 tune and 250 draw iterations (20_000 + 1_000 draws total) took 4794 seconds.\n",
      "There were 229 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCMC Summary:\n",
      "             mean        sd  hdi_3%    hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
      "tau_idx   49.5040   31.9015  0.0000    89.0000    10.0447   2.2037    9.9592   \n",
      "mu_1       0.0002    0.0012 -0.0015     0.0025     0.0001   0.0002  167.8062   \n",
      "mu_2      -0.0002    0.0007 -0.0014     0.0007     0.0003   0.0001    7.2100   \n",
      "sigma      0.0107    0.0002  0.0105     0.0111     0.0000   0.0000  107.6897   \n",
      "tau      990.0800  638.0300  0.0000  1780.0000   200.8947  44.0732    9.9592   \n",
      "\n",
      "         ess_tail   r_hat  \n",
      "tau_idx   36.5863  1.3428  \n",
      "mu_1      68.9762  1.1029  \n",
      "mu_2      22.1524  1.5439  \n",
      "sigma    165.1581  1.0440  \n",
      "tau       36.5863  1.3428  \n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Build and Run Change Point Model\n",
    "# Description: Build the Bayesian model and run MCMC sampling.\n",
    "# Input: Log returns array and number of weeks\n",
    "# Output: PyMC model and InferenceData trace\n",
    "\n",
    "# Build model\n",
    "model = build_changepoint_model(log_returns, n_days)\n",
    "\n",
    "# Run MCMC sampling with optimized parameters\n",
    "trace = run_mcmc(model, n_days, log_returns, draws=250, tune=5000)\n",
    "\n",
    "# Check convergence\n",
    "print(\"MCMC Summary:\")\n",
    "print(az.summary(trace, round_to=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c856614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Visualize Model Results\n",
    "# Description: Plot log returns with estimated change point and posterior distribution of tau.\n",
    "# Input: MCMC trace, log returns data, and dates\n",
    "# Output: Plot saved to 'results/figures/changepoint_results.png'\n",
    "\n",
    "# Define output path\n",
    "OUTPUT_PATH = '../results/figures/changepoint_results.png'\n",
    "\n",
    "# Plot results\n",
    "plot_changepoint_results(trace, log_returns, dates, OUTPUT_PATH)\n",
    "\n",
    "# Display plot (already saved)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change Point Interpretation:\n",
      "change_point_date: 2006-05-14\n",
      "associated_event: Global Financial Crisis\n",
      "event_date: 2008-09-15\n",
      "event_description: Lehman collapse triggers global recession and a dramatic oil demand drop\n",
      "log_return_change: -0.0003\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Interpret Change Point Results\n",
    "# Description: Associate change point with events and quantify impact on log returns.\n",
    "# Input: MCMC trace, dates, and events DataFrame\n",
    "# Output: Dictionary with interpretation results\n",
    "\n",
    "# Interpret results\n",
    "results = interpret_changepoint(trace, dates, events_df)\n",
    "\n",
    "# Print interpretation\n",
    "print(\"Change Point Interpretation:\")\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
