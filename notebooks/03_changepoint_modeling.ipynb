{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 1: Introduction to Change Point Modeling\n",
    "\n",
    "**Purpose**: This notebook implements a Bayesian change point model using PyMC to detect structural breaks in Brent oil price log returns and associate them with major events for the 10 Academy Week 10 Challenge (Task 2).\n",
    "\n",
    "**Objectives**:\n",
    "- Load and prepare preprocessed Brent oil price data.\n",
    "- Build and run a Bayesian change point model on log returns.\n",
    "- Interpret results to identify change points and quantify impacts.\n",
    "- Associate change points with events from `major_events.csv`.\n",
    "\n",
    "**Input**: `data/processed/cleaned_oil_data.csv`, `data/events/major_events.csv`\n",
    "**Output**: Plots in `results/figures/`, model results in `results/models/`, and interpretation dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99de8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import Required Libraries\n",
    "# Description: Import Python libraries for modeling, data handling, and visualization.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "# Add the project root directory\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from src.models.changepoint_model import build_changepoint_model, run_mcmc, plot_changepoint_results, interpret_changepoint\n",
    "\n",
    "# Ensure plots are displayed inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c01d9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price Data Head:\n",
      "        Date  Price  Log_Price  Log_Returns\n",
      "0 1987-05-20  18.63   2.924773          NaN\n",
      "1 1987-05-21  18.45   2.915064    -0.009709\n",
      "2 1987-05-22  18.55   2.920470     0.005405\n",
      "3 1987-05-25  18.60   2.923162     0.002692\n",
      "4 1987-05-26  18.63   2.924773     0.001612\n",
      "\n",
      "Events Data Head:\n",
      "                Event Name  Start Date         Category  \\\n",
      "0          Gulf War Begins  1990-08-02         Conflict   \n",
      "1   Asian Financial Crisis  1997-07-02   Economic Shock   \n",
      "2             9/11 Attacks  2001-09-11  Political Shock   \n",
      "3          Iraq War Begins  2003-03-20         Conflict   \n",
      "4  Global Financial Crisis  2008-09-15   Economic Shock   \n",
      "\n",
      "                                         Description  \\\n",
      "0  Iraq invades Kuwait; major geopolitical shock ...   \n",
      "1  Currency collapse across Asia affects global d...   \n",
      "2  Terror attacks create market instability and e...   \n",
      "3  U.S. invasion leads to long-term shifts in Mid...   \n",
      "4  Lehman collapse triggers global recession and ...   \n",
      "\n",
      "                                         Source Link  \n",
      "0             https://en.wikipedia.org/wiki/Gulf_War  \n",
      "1  https://www.investopedia.com/terms/a/asian-fin...  \n",
      "2  https://en.wikipedia.org/wiki/September_11_att...  \n",
      "3  https://www.history.com/topics/middle-east/ira...  \n",
      "4  https://www.imf.org/en/Publications/WP/Issues/...  \n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load Preprocessed Data\n",
    "# Description: Load preprocessed Brent oil price data and major events dataset.\n",
    "# Input: Preprocessed CSV file and events CSV file\n",
    "# Output: DataFrames for prices and events\n",
    "\n",
    "# Define file paths\n",
    "PRICE_PATH = '../data/processed/cleaned_oil_data.csv'\n",
    "EVENTS_PATH = '../data/events/major_events.csv'\n",
    "\n",
    "# Load price data\n",
    "price_df = pd.read_csv(PRICE_PATH, parse_dates=['Date'])\n",
    "\n",
    "# Load events data with quoting to handle commas in text fields\n",
    "events_df = pd.read_csv(EVENTS_PATH, quotechar='\"', quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "# Display first few rows to verify\n",
    "print(\"Price Data Head:\")\n",
    "print(price_df.head())\n",
    "print(\"\\nEvents Data Head:\")\n",
    "print(events_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "184d4cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days: 1853\n",
      "Log returns range: -0.0647 to 0.0676\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Prepare Data for Modeling\n",
    "# Description: Extract log returns and dates for change point modeling.\n",
    "# Input: Preprocessed DataFrame\n",
    "# Output: Numpy array of log returns and Series of dates\n",
    "\n",
    "# Drop rows with NaN log returns (first row due to diff)\n",
    "model_df = price_df.dropna(subset=['Log_Returns'])\n",
    "\n",
    "# Extract log returns as numpy array\n",
    "log_returns = model_df['Log_Returns'].values\n",
    "\n",
    "# Extract corresponding dates\n",
    "dates = model_df['Date']\n",
    "\n",
    "# Get number of days\n",
    "n_days = len(log_returns)\n",
    "\n",
    "# Downsample to weekly data\n",
    "model_df = model_df.resample('W', on='Date').mean().reset_index()\n",
    "log_returns = model_df['Log_Returns'].values\n",
    "dates = model_df['Date']\n",
    "n_days = len(log_returns)\n",
    "\n",
    "# Print data summary\n",
    "print(f\"Number of days: {n_days}\")\n",
    "print(f\"Log returns range: {log_returns.min():.4f} to {log_returns.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dd93007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "CompoundStep\n",
      ">Metropolis: [tau_cont]\n",
      ">NUTS: [mu_1, mu_2, sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\hp\\Desktop\\projects\\10 Acadamy \n",
       "-KAIM5\\brent-oil-changepoint-analysis\\.venv\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\hp\\Desktop\\projects\\10 Acadamy \n",
       "-KAIM5\\brent-oil-changepoint-analysis\\.venv\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 500 tune and 500 draw iterations (2_000 + 2_000 draws total) took 4000 seconds.\n",
      "There were 203 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCMC Summary:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can only convert xarray dataarray, xarray dataset, dict, pytree (if 'dm-tree' is installed), netcdf filename, numpy array, pystan fit, emcee fit, pyro mcmc fit, numpyro mcmc fit, cmdstan fit csv filename, cmdstanpy fit to InferenceData, not MultiTrace",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Check convergence\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMCMC Summary:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpm\u001b[49m\u001b[43m.\u001b[49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\Desktop\\projects\\10 Acadamy -KAIM5\\brent-oil-changepoint-analysis\\.venv\\Lib\\site-packages\\arviz\\stats\\stats.py:1366\u001b[39m, in \u001b[36msummary\u001b[39m\u001b[34m(data, var_names, filter_vars, group, fmt, kind, round_to, circ_var_names, stat_focus, stat_funcs, extend, hdi_prob, skipna, labeller, coords, index_origin, order)\u001b[39m\n\u001b[32m   1364\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInferenceData does not contain group: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroup\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1366\u001b[39m     dataset = \u001b[43mconvert_to_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mposterior\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1367\u001b[39m var_names = _var_names(var_names, dataset, filter_vars)\n\u001b[32m   1368\u001b[39m dataset = dataset \u001b[38;5;28;01mif\u001b[39;00m var_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dataset[var_names]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\Desktop\\projects\\10 Acadamy -KAIM5\\brent-oil-changepoint-analysis\\.venv\\Lib\\site-packages\\arviz\\data\\converters.py:185\u001b[39m, in \u001b[36mconvert_to_dataset\u001b[39m\u001b[34m(obj, group, coords, dims)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert_to_dataset\u001b[39m(obj, *, group=\u001b[33m\"\u001b[39m\u001b[33mposterior\u001b[39m\u001b[33m\"\u001b[39m, coords=\u001b[38;5;28;01mNone\u001b[39;00m, dims=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    148\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Convert a supported object to an xarray dataset.\u001b[39;00m\n\u001b[32m    149\u001b[39m \n\u001b[32m    150\u001b[39m \u001b[33;03m    This function is idempotent, in that it will return xarray.Dataset functions\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    183\u001b[39m \u001b[33;03m    xarray.Dataset\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     inference_data = \u001b[43mconvert_to_inference_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m     dataset = \u001b[38;5;28mgetattr\u001b[39m(inference_data, group, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\Desktop\\projects\\10 Acadamy -KAIM5\\brent-oil-changepoint-analysis\\.venv\\Lib\\site-packages\\arviz\\data\\converters.py:139\u001b[39m, in \u001b[36mconvert_to_inference_data\u001b[39m\u001b[34m(obj, group, coords, dims, **kwargs)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    125\u001b[39m     allowable_types = (\n\u001b[32m    126\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mxarray dataarray\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    127\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mxarray dataset\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    137\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcmdstanpy fit\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    138\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    140\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCan only convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(allowable_types)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to InferenceData, \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    141\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    142\u001b[39m     )\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m InferenceData(**{group: dataset})\n",
      "\u001b[31mValueError\u001b[39m: Can only convert xarray dataarray, xarray dataset, dict, pytree (if 'dm-tree' is installed), netcdf filename, numpy array, pystan fit, emcee fit, pyro mcmc fit, numpyro mcmc fit, cmdstan fit csv filename, cmdstanpy fit to InferenceData, not MultiTrace"
     ]
    }
   ],
   "source": [
    "# Cell 5: Build and Run Change Point Model\n",
    "# Description: Build the Bayesian model and run MCMC sampling.\n",
    "# Input: Log returns array and number of days\n",
    "# Output: PyMC model and MCMC trace\n",
    "\n",
    "# Build model\n",
    "model = build_changepoint_model(log_returns, n_days)\n",
    "\n",
    "# Run MCMC sampling with fewer draws for faster execution\n",
    "trace = run_mcmc(model, draws=500, tune=500)\n",
    "\n",
    "# Check convergence\n",
    "print(\"MCMC Summary:\")\n",
    "print(pm.summary(trace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6a02bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Visualize Model Results\n",
    "# Description: Plot log returns with estimated change point and posterior distribution of tau.\n",
    "# Input: MCMC trace, log returns data, and dates\n",
    "# Output: Plot saved to 'results/figures/changepoint_results.png'\n",
    "\n",
    "# Define output path\n",
    "OUTPUT_PATH = '../results/figures/changepoint_results.png'\n",
    "\n",
    "# Plot results\n",
    "plot_changepoint_results(trace, log_returns, dates, OUTPUT_PATH)\n",
    "\n",
    "# Display plot (already saved)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Interpret Change Point Results\n",
    "# Description: Associate change point with events and quantify impact on log returns.\n",
    "# Input: MCMC trace, dates, and events DataFrame\n",
    "# Output: Dictionary with interpretation results\n",
    "\n",
    "# Interpret results\n",
    "results = interpret_changepoint(trace, dates, events_df)\n",
    "\n",
    "# Print interpretation\n",
    "print(\"Change Point Interpretation:\")\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
